name: Test & Benchmark

on:
  pull_request:
    branches: [main]
    paths:
      - 'java/**'
      - 'tests/benchmark/**'
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '21'

      - name: Setup uv
        uses: astral-sh/setup-uv@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Setup pnpm
        run: npm install -g pnpm

      - name: Build & Test All
        run: ./scripts/build-all.sh

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v5
        with:
          files: java/opendataloader-pdf-core/target/site/jacoco/jacoco.xml
          fail_ci_if_error: true
          token: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: java-build
          path: java/opendataloader-pdf-cli/target/*.jar
          retention-days: 1

  benchmark:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '21'

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: java-build
          path: java/opendataloader-pdf-cli/target/

      - name: Setup uv
        uses: astral-sh/setup-uv@v4

      - name: Run benchmark with regression check
        run: |
          cd tests/benchmark
          uv sync --quiet
          uv run python run.py --check-regression

      - name: Fetch baseline from main
        run: |
          git fetch origin main
          git show origin/main:tests/benchmark/prediction/opendataloader/evaluation.json > /tmp/baseline.json || echo '{}' > /tmp/baseline.json

      - name: Comment benchmark results on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            // í˜„ìž¬ ê²°ê³¼ ë¡œë“œ
            const current = JSON.parse(fs.readFileSync('tests/benchmark/prediction/opendataloader/evaluation.json', 'utf8'));

            // baseline ë¡œë“œ (ì—†ìœ¼ë©´ ë¹ˆ ê°ì²´)
            let baseline = {};
            try {
              baseline = JSON.parse(fs.readFileSync('/tmp/baseline.json', 'utf8'));
            } catch (e) {}

            const m = current.metrics.score;
            const b = baseline.metrics?.score || {};
            const td = current.table_detection || {};
            const btd = baseline.table_detection || {};

            const fmt = (v) => v != null ? v.toFixed(3) : '-';
            const diff = (curr, base) => {
              if (curr == null || base == null) return '-';
              const pct = ((curr - base) / base * 100);
              const sign = pct >= 0 ? '+' : '';
              return `${sign}${pct.toFixed(1)}%`;
            };

            const body = `## ðŸ“Š Benchmark Results

            ### Scores
            | Metric | Score | Baseline | Change |
            |--------|-------|----------|--------|
            | **NID** | ${fmt(m.nid_mean)} | ${fmt(b.nid_mean)} | ${diff(m.nid_mean, b.nid_mean)} |
            | **TEDS** | ${fmt(m.teds_mean)} | ${fmt(b.teds_mean)} | ${diff(m.teds_mean, b.teds_mean)} |
            | **MHS** | ${fmt(m.mhs_mean)} | ${fmt(b.mhs_mean)} | ${diff(m.mhs_mean, b.mhs_mean)} |

            ### Table Detection
            | Metric | Score | Baseline | Change |
            |--------|-------|----------|--------|
            | **F1** | ${fmt(td.f1)} | ${fmt(btd.f1)} | ${diff(td.f1, btd.f1)} |
            | **Precision** | ${fmt(td.precision)} | ${fmt(btd.precision)} | ${diff(td.precision, btd.precision)} |
            | **Recall** | ${fmt(td.recall)} | ${fmt(btd.recall)} | ${diff(td.recall, btd.recall)} |

            <details>
            <summary>Details</summary>

            - Documents: ${current.summary.document_count}
            - Commit: \`${context.sha.substring(0, 7)}\`

            </details>
            `;

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: body
            });

      - name: Upload evaluation results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: benchmark-results
          path: tests/benchmark/prediction/opendataloader/evaluation.json
