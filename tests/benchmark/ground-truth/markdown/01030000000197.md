# C Additional Information

We present additional information for the sake of
space in the main paper.

Filtered task names. We present task names
we use to filter FLAN dervied datasets such as
OpenOrca in Table 8.

<table>
 <tr>
  <td>
   Filtered Task Name
  </td>
  <td>
   task228_arc_answer_generation_easy ai2_arcARCChallenge:1.0.0 ai2_arcARCEasy:1.0.0 task229_arc_answer_generation_hard hellaswag:1.1.0 task1389_hellaswag_completion cot_gsm8k cot_gsm8k_ii drop:2.0.0 winogrande:1.1.0
  </td>
 </tr>
</table>


Table 8: Task names that we use to filter data for FLAN
derived datasets such as OpenOrca.

<table>
 <tr>
  <td>
   ARC
  </td>
  <td>
   HellaSwag
  </td>
  <td>
   MMLU
  </td>
  <td>
   TruthfulQA
  </td>
  <td>
   Winogrande
  </td>
  <td>
   GSM8K
  </td>
 </tr>
 <tr>
  <td>
   0.06
  </td>
  <td>
   N/A
  </td>
  <td>
   0.15
  </td>
  <td>
   0.28
  </td>
  <td>
   N/A
  </td>
  <td>
   0.70
  </td>
 </tr>
</table>


Table 9: Data contamination test results for SOLAR
10.7B-Instruct. We show 'result < 0.1, %' values where
a value higher than 0.9 indicates high probability of data
contamination. HellaSwag and Winogrande datasets are
not currently supported. We set SOLAR 10.7B as our
reference model when performing the data contamina-
tion tests.

Results on data contamination. To show the in-
tegrity of SOLAR 10.7B-Instruct, we also report
the data contamination test (Shi et al., 2023) results
in Table. 9. All four tested benchmark datasets
yield results well below the contamination thresh-
old, affirming the absence of data contamination
in our model. One interesting point is that the
value for GSM8K is noticeably higher than for
other datasets, even without contamination. One
potential reason for this is the stronger data similar-
ity in math-related instruction datasets.