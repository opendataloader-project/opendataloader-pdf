316

YARROW

where SOAS below some threshold cannot be recovered, SO that an observer
can only guess about order1g However, eitherkind ofmodel can easily befitted
and interpreted from either theoretical perspective.

# 8 Choosing between Observer Models and Rejecting Participants

Two further reasonable questions one might ask are: 1) could my observer
model have generated these data? and 2) does another observer model de-
scribe the data better? Model comparison is large and complex topic, SO once
again, what have to say here should be treated as a brief introduction rather
than a comprehensive summary.

Let's begin by considering a metric have not yet mentioned: Deviance. De-
viance (sometimes called G2) is a measure based on log likelihood, but which
looks rather more like summed squared error, in that it is zero for a perfectly
fitting model and large/positive for poorly fitting model. Formally, deviance
is two times the difference in log likelihood between the saturated model and
the model with our current set of parameters. A saturated model is one that
exactly predicts the data (which can always be accomplished by a model that
has one parameter per data point). Hence it represents the situation with the
maximum possible log-likelihood when predicting this particular set of data.
Deviance is closely related to a simpler calculation (-2 X log likelihood) that
forms the basis ofa couple of well-known metrics for model comparison (the
Akaike information criterion, AIC, and the Bayesian information criterion,
BIC) and indeed is occasionally defined this way. That's because we are of-
ten only really interested in differences (in Deviance, OrAIC,orbic) between
models, and the log-likelihood of the saturated model gets subtracted out in a
comparison between two models (because it has contributed to the deviance
in the same way for both) SO calculating itis not necessary.

However, iffou want to say something about the goodness offit ofa model
without relating it to any other model, based on asymptotic statistical theory,
you do need to calculate deviance properly. Asymptotically it turns out that
the deviance ofa model fitted to data when that model actually generated those
data follows a chi-square (x3) distribution, with degrees of freedom equal to
the number of data points minus the number of model parameters (note:for

19 Garcia-Perez and Alcala-Quintana's commitment to this account is a little unclear, be-
cause they often let 8 vary across experimental conditions, suggesting flexibility more
akin to criterion-based account. Itmay be that they believe low-threshold exists, but
thatsynchrony is often additionally reported beyond this hard limit.

